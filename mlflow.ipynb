{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, \n",
    "    SplineTransformer, \n",
    "    QuantileTransformer, \n",
    "    RobustScaler,\n",
    "    PolynomialFeatures,\n",
    "    KBinsDiscretizer,\n",
    ")\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.xcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = \"AP2T\"\n",
    "RUN_NAME = \"preprocessing\" \n",
    "REGISTRY_MODEL_NAME = \"test_01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_df = df.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(obj_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features\n",
    "cat_columns = [\"type\", \"payment_method\", \"internet_service\", \"gender\"]\n",
    "\n",
    "# creating a OneHotEncoder object\n",
    "encoder_oh = OneHotEncoder(categories='auto', handle_unknown='ignore', max_categories=10, sparse_output=False, drop='first')\n",
    "\n",
    "# applying OneHotEncoder\n",
    "encoded_features = encoder_oh.fit_transform(df[cat_columns])\n",
    "\n",
    "# features transformation\n",
    "encoded_df = encoder_oh.get_feature_names_out(cat_columns)\n",
    "encoded_feature_names = encoder_oh.get_feature_names_out(cat_columns)\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names, index=df.index)\n",
    "\n",
    "obj_df = pd.concat([obj_df, encoded_df], axis=1)\n",
    "\n",
    "obj_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [\"monthly_charges\", \"total_charges\"]\n",
    "\n",
    "n_knots = 3\n",
    "degree_spline = 4\n",
    "n_quantiles=100\n",
    "degree = 3\n",
    "n_bins = 5\n",
    "encode = 'ordinal'\n",
    "strategy = 'uniform'\n",
    "subsample = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[num_columns].isna().sum())\n",
    "print(df[num_columns].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_columns] = df[num_columns].fillna(df[num_columns].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[num_columns].isna().sum())\n",
    "print(df[num_columns].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = df[num_columns]\n",
    "\n",
    "# SplineTransformer\n",
    "encoder_spl = SplineTransformer(n_knots=n_knots, degree=degree_spline)\n",
    "encoded_features = encoder_spl.fit_transform(df[num_columns].to_numpy())\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_features, \n",
    "    columns=encoder_spl.get_feature_names_out(num_columns)\n",
    ")\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# QuantileTransformer\n",
    "encoder_q = QuantileTransformer(n_quantiles=n_quantiles)\n",
    "encoded_features = encoder_q.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_q.get_feature_names_out(num_columns))\n",
    "encoded_df.columns = [col + f\"_q_{n_quantiles}\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# RobustScaler\n",
    "encoder_rb = RobustScaler()\n",
    "encoded_features = encoder_rb.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_rb.get_feature_names_out(num_columns))\n",
    "encoded_df.columns = [col + f\"_robust\" for col in num_columns]\n",
    "num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# PolynomialFeatures\n",
    "encoder_pol = PolynomialFeatures(degree=degree)\n",
    "encoded_features = encoder_pol.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_pol.get_feature_names_out(num_columns))\n",
    "encoded_df.drop(encoded_df.columns[:1 + len(num_columns)], axis=1, inplace=True)\n",
    "\n",
    "# KBinsDiscretizer\n",
    "encoder_kbd = KBinsDiscretizer(n_bins=n_bins, encode=encode, strategy=strategy, subsample=subsample)\n",
    "encoded_features = encoder_kbd.fit_transform(df[num_columns].to_numpy())\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder_kbd.get_feature_names_out(num_columns))\n",
    "encoded_df.columns = [col + f\"_bin\" for col in num_columns]\n",
    "num_df = num_df = pd.concat([num_df, encoded_df], axis=1)\n",
    "\n",
    "\n",
    "num_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = ColumnTransformer(\n",
    "    transformers=[('spl', encoder_spl, num_columns), \n",
    "                  ('q', encoder_q, num_columns), \n",
    "                  ('rb', encoder_rb, num_columns), \n",
    "                  ('pol', encoder_pol, num_columns), \n",
    "                  ('kbd', encoder_kbd, num_columns)])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[('encoder', encoder_oh)])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, num_columns), \n",
    "('cat', categorical_transformer, cat_columns)], n_jobs=-1)\n",
    "\n",
    "encoded_features = preprocessor.fit_transform(df)\n",
    "\n",
    "transformed_df = pd.DataFrame(encoded_features, columns=preprocessor.get_feature_names_out())\n",
    "\n",
    "df = pd.concat([df, transformed_df], axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/07 16:42:42 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da026a10c333400da167ea17798bd355\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.xcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "\n",
    "EXPERIMENT_NAME = \"AP2T\"\n",
    "RUN_NAME = \"preprocessing\" \n",
    "REGISTRY_MODEL_NAME = \"test_01\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "mlflow.set_registry_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "    print(run_id)\n",
    "    mlflow.sklearn.log_model(preprocessor, \"column_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from category_encoders import CatBoostEncoder\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(df, df['target'], stratify=df['target'])\n",
    "\n",
    "cat_features = df.select_dtypes(include='object')\n",
    "potential_binary_features = cat_features.nunique() == 2\n",
    "binary_cat_features = cat_features[potential_binary_features[potential_binary_features].index]\n",
    "other_cat_features = cat_features[potential_binary_features[~potential_binary_features].index]\n",
    "num_features = df.select_dtypes(['float']) \n",
    "binary_cols = binary_cat_features.columns.tolist()\n",
    "non_binary_cat_cols = other_cat_features.columns.tolist()\n",
    "num_cols = num_features.columns.tolist()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "    ('binary', OneHotEncoder(drop='if_binary'), binary_cols),\n",
    "    ('cat', CatBoostEncoder(), non_binary_cat_cols),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "model = CatBoostClassifier(auto_class_weights='Balanced')\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(df, df['target'])\n",
    "\n",
    "y_pred = pipeline.predict(X_val)\n",
    "y_pred_proba = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print('f1:', f1_score(y_val, y_pred))\n",
    "print('roc_auc:', roc_auc_score(y_val, y_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "EXPERIMENT_NAME = \"outflow_fio\"\n",
    "RUN_NAME = \"model0_reg\"\n",
    "REGISTRY_MODEL_NAME = \"outflow_model_ap\"\n",
    "\n",
    "\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"https://storage.xcloud.net\"\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "\n",
    "pip_requirements = \"requirements.txt\"\n",
    "signature = mlflow.models.infer_signature(X_test, prediction)\n",
    "input_example = X_test[:10]\n",
    "metadata = {'model_type': 'monthly'}\n",
    "\n",
    "\n",
    "experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME).experiment_id\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    model_info = mlflow.catboost.log_model( \n",
    "        cb_model=model,\n",
    "        await_registration_for=60,\n",
    "        artifact_path=\"models\",\n",
    "        pip_requirements=pip_requirements,\n",
    "        input_example=input_example,\n",
    "        metadata=metadata,\n",
    "        signature=signature,\n",
    "        registered_model_name=REGISTRY_MODEL_NAME,\t\t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle-mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
